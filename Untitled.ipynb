{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = numpy.loadtxt(\"pa3train.txt\")\n",
    "test = numpy.loadtxt(\"pa3test.txt\")\n",
    "feature_len = len(train[0])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(number):\n",
    "    return 1 if number >= 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_percepie_boy(train, passes, label_one):\n",
    "    w = numpy.zeros(feature_len)\n",
    "\n",
    "    for p in range(passes):\n",
    "        for point in train:\n",
    "            label = 1 if label_one == point[feature_len] else -1\n",
    "            if  label * numpy.dot(w, point[:feature_len]) <= 0:\n",
    "                w = w + (label * point[:feature_len])\n",
    "\n",
    "    return w\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron_error(test, w, label):\n",
    "    wrong = 0\n",
    "    for point in test:\n",
    "        sign = numpy.dot(w, point[:feature_len])\n",
    "        if  sign < 0 and point[feature_len] == label:\n",
    "            wrong += 1\n",
    "        elif sign >= 0 and point[feature_len] != label:\n",
    "            wrong += 1\n",
    "     \n",
    "    return wrong/len(test)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_voted_perceptron(train, passes, label_one):\n",
    "    w = numpy.zeros(feature_len)\n",
    "    c = 1\n",
    "    classifiers = []\n",
    "    for p in range(passes):\n",
    "        for point in train:\n",
    "            label = 1 if label_one == point[feature_len] else -1\n",
    "            if  label * numpy.dot(w, point[:feature_len]) <= 0:\n",
    "                classifiers.append((w, c))\n",
    "                w = w + (label * point[:feature_len])\n",
    "                c = 1 \n",
    "            else:\n",
    "                c += 1\n",
    "\n",
    "    classifiers.append((w, c))\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voted_perceptron_error(test, classifiers, label):\n",
    "    wrong  = 0\n",
    "    \n",
    "    for point in test:\n",
    "        test_feat = point[:feature_len]\n",
    "        pred = 0\n",
    "        for c in classifiers:\n",
    "            pred += c[1] * sign(numpy.dot(c[0], test_feat))\n",
    "        if sign(pred) < 0 and point[feature_len] == label:\n",
    "            wrong += 1 \n",
    "        elif sign(pred) >= 0 and point[feature_len] != label:\n",
    "            wrong += 1\n",
    "    return wrong/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_perceptron_error(test, classifers, label):\n",
    "    wrong = 0\n",
    "    w = sum([classi[0] * classi[1] for classi in classifers])\n",
    "    for point in test:\n",
    "        sign = numpy.dot(w, point[:feature_len])\n",
    "        if  sign < 0 and point[feature_len] == label:\n",
    "            wrong += 1\n",
    "        elif sign >= 0 and point[feature_len] != label:\n",
    "            wrong += 1   \n",
    "    return wrong/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_two_subset = [point for point in train if point[len(point)-1] == 1 or point[len(point)-1] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01651376146788991"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = train_percepie_boy(one_two_subset, 4, 1)\n",
    "perceptron_error(one_two_subset, w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022018348623853212"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classis = train_voted_perceptron(one_two_subset, 4, 1)\n",
    "voted_perceptron_error(one_two_subset, classis, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031192660550458717"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classis = train_voted_perceptron(one_two_subset, 4, 1)\n",
    "average_perceptron_error(one_two_subset, classis, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 3:\n",
      "['file']\n",
      "['program']\n",
      "['line']\n",
      "bot 3:\n",
      "['he']\n",
      "['team']\n",
      "['game']\n"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest, nsmallest\n",
    "\n",
    "classis = train_voted_perceptron(one_two_subset, 3, 1, 2)\n",
    "w = sum([classi[0] * classi[1] for classi in classis])\n",
    "\n",
    "top = nlargest(3, enumerate(w), key=lambda x:x[1])  # returns list of (index, value)\n",
    "bot = nsmallest(3, enumerate(w), key=lambda x:x[1])  # returns list of (index, value)\n",
    "\n",
    "diction = []\n",
    "\n",
    "for line in open(\"pa3dictionary.txt\", 'r'):\n",
    "    diction.append(line.strip().split('/n')) \n",
    "\n",
    "print(\"top 3:\")\n",
    "print(diction[top[0][0]])\n",
    "print(diction[top[1][0]])\n",
    "print(diction[top[2][0]])\n",
    "print(\"bot 3:\")\n",
    "print(diction[bot[0][0]])\n",
    "print(diction[bot[1][0]])\n",
    "print(diction[bot[2][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_vs_all(train):\n",
    "    classis = []\n",
    "    for label in range(1,7):\n",
    "        classis.append(train_percepie_boy(train, 1, label))\n",
    "    return classis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all(test, classifiers):\n",
    "    preds = []\n",
    "    for point in test:\n",
    "        pred = [sign(numpy.dot(classi, point[:feature_len])) for classi in classifiers]\n",
    "        if sum(pred) == -4:\n",
    "            preds.append(pred.index(1)+1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0]\n",
      " [ 43 133   2   0   3   3   1]\n",
      " [ 52   2 126   3   1   6   2]\n",
      " [ 79   6   6  65   0  13   6]\n",
      " [ 48   4   5   0 126   1   0]\n",
      " [ 18   0   2   0   0 125  11]\n",
      " [ 36   0   2   3   0  13  54]]\n",
      "[[ 0.23243243  0.27083333  0.45142857  0.26086957  0.11538462  0.33333333]\n",
      " [ 0.71891892  0.01041667  0.03428571  0.02173913  0.          0.        ]\n",
      " [ 0.01081081  0.65625     0.03428571  0.02717391  0.01282051  0.01851852]\n",
      " [ 0.          0.015625    0.37142857  0.          0.          0.02777778]\n",
      " [ 0.01621622  0.00520833  0.          0.68478261  0.          0.        ]\n",
      " [ 0.01621622  0.03125     0.07428571  0.00543478  0.80128205  0.12037037]\n",
      " [ 0.00540541  0.01041667  0.03428571  0.          0.07051282  0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "classis = train_one_vs_all(train)\n",
    "preds = one_vs_all(test, classis)\n",
    "actual = [point[feature_len] for point in test]\n",
    "con_mat = confusion_matrix(actual, preds)\n",
    "print(con_mat)\n",
    "con_mat = con_mat.astype(numpy.float64)\n",
    "con_mat = normalize(con_mat, norm='l1')\n",
    "con_mat = con_mat[1:]\n",
    "con_mat = con_mat.transpose()\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
